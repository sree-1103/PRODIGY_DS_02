# Prodigy DS task 02
🚢 Titanic Dataset – Data Cleaning & Exploratory Data Analysis
EDA | Data Cleaning | Python | Kaggle Dataset

🔍 Project Summary
Dove deep into the Titanic dataset from Kaggle to perform comprehensive data cleaning and exploratory data analysis (EDA). This project reveals the hidden stories behind the data—uncovering patterns, correlations, and outliers that set the stage for informed decision-making and predictive modeling.

By transforming raw, unstructured data into clean and insightful visualizations, this project serves as a critical foundation for any downstream analytics or machine learning efforts.

🧰 Tools & Technologies
Python Libraries: Pandas, NumPy, Matplotlib, Seaborn

Techniques: Handling missing values, outlier detection, data visualization, correlation analysis

Dataset Source: Kaggle – Titanic: Machine Learning from Disaster

📊 Process Breakdown
1. Data Cleaning
Identified and handled missing values in key columns like Age, Cabin, and Embarked

Converted data types and formatted categorical variables for consistency

Removed or transformed irrelevant and redundant features

2. Exploratory Data Analysis (EDA)
Visualized relationships between variables (e.g., survival vs. gender/class/age)

Used histograms, box plots, heatmaps, and count plots to identify trends and distributions

Analyzed correlation between features to inform future feature selection and modeling

3. Key Findings
Higher survival rates among women and first-class passengers

Younger passengers had slightly higher survival chances

Strong relationships between Pclass, Sex, and Survival

💡 Key Insights
EDA uncovers real-world patterns that may not be immediately visible in raw data

Effective cleaning ensures data quality and integrity for modeling

Titanic data is a powerful learning tool for understanding variable interactions and feature importance

🚀 What I Learned
Practical approaches to cleaning messy, incomplete datasets

How to explore data visually and statistically to draw insights

The importance of EDA in shaping effective data-driven solutions
